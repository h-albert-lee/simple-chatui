"""Streamlit application entry point."""

from __future__ import annotations

from typing import List

import streamlit as st
from dotenv import load_dotenv

from chatbot.frontend import api_client, session_manager, ui_component

load_dotenv()

st.set_page_config(page_title="Simple ChatUI", page_icon="ğŸ’¬", layout="wide")

session_manager.initialize_session()
ui_component.render_sidebar()

current_chat = session_manager.get_current_chat()

if not current_chat or not current_chat.get("messages"):
    st.title("ê°„ë‹¨í•œ ChatGPT ìŠ¤íƒ€ì¼ ì¸í„°í˜ì´ìŠ¤")
    st.write(
        "ì¢Œì¸¡ ì‚¬ì´ë“œë°”ì—ì„œ ìƒˆ ëŒ€í™”ë¥¼ ì‹œì‘í•˜ê³ , ëª¨ë¸ì„ ì„ íƒí•œ ë’¤ ë©”ì‹œì§€ë¥¼ ì…ë ¥í•´ë³´ì„¸ìš”."
    )
else:
    ui_component.render_chat_history(current_chat)

prompt = st.chat_input("ë©”ì‹œì§€ë¥¼ ì…ë ¥í•˜ì„¸ìš”â€¦")

if prompt:
    if not current_chat:
        session_manager.create_new_chat()
        current_chat = session_manager.get_current_chat()

    session_manager.append_message("user", prompt)
    current_chat = session_manager.get_current_chat()

    with st.chat_message("user"):
        st.markdown(prompt)

    session_manager.update_title_if_needed(prompt)

    model_name = session_manager.get_selected_model()

    with st.chat_message("assistant"):
        collected_chunks: List[str] = []
        response_container = st.empty()
        try:
            for chunk in api_client.stream_chat_completion(
                current_chat["messages"], model=model_name
            ):
                collected_chunks.append(chunk)
                response_container.markdown("".join(collected_chunks))
        except Exception as exc:  # broad to display feedback in UI
            st.error(f"ì‘ë‹µì„ ê°€ì ¸ì˜¤ëŠ” ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤: {exc}")
        else:
            full_response = "".join(collected_chunks)
            if full_response:
                session_manager.append_message("assistant", full_response)

    st.experimental_rerun()
