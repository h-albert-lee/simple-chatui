# ==================================
# Backend Settings
# ==================================
# FastAPI 서버가 실행될 호스트 및 포트
BACKEND_HOST="0.0.0.0"
BACKEND_PORT=8888
# 로그 레벨 (DEBUG, INFO, WARNING, ERROR)
LOG_LEVEL="INFO"

# ==================================
# vLLM Server (OpenAI Compatible)
# ==================================
# 연결할 AI 모델 서버의 주소
VLLM_API_URL="http://localhost:8000/v1/chat/completions"

# ==================================
# Frontend Settings
# ==================================
# 프론트엔드가 접속할 백엔드 API의 전체 주소
# 참고: backend/main.py의 API 라우터 prefix ('/api/v1')가 포함되어야 합니다.
FRONTEND_BACKEND_URL="http://localhost:8888/api/v1/chat/stream"

# ==================================
# CORS Settings
# ==================================
# 백엔드에 접속을 허용할 프론트엔드 주소 (쉼표로 여러 개 추가 가능)
CORS_ORIGINS_STR="http://localhost:8501"